"""
Main Chatbot - K·∫øt h·ª£p AI training v√† job search
"""
import os
import sys

# Disable TensorFlow - Ch·ªâ d√πng PyTorch
os.environ['TRANSFORMERS_NO_TF'] = '1'
os.environ['USE_TORCH'] = '1'

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.ai_trainer import AITrainer
from core.db_connector import DatabaseConnector
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings

# AI SQL Generator
try:
    from core.ai_sql_generator import SmartSQLExecutor, add_execute_methods_to_db_connector
    AI_SQL_AVAILABLE = True
    # Add execute methods to DatabaseConnector
    add_execute_methods_to_db_connector()
except ImportError as e:
    print(f"‚ö†Ô∏è AI SQL Generator not available: {e}")
    AI_SQL_AVAILABLE = False


class HRChatbot:
    """HR Chatbot v·ªõi AI training v√† job search"""
    
    def __init__(self):
        print("üöÄ Kh·ªüi t·∫°o HR Chatbot...")
        
        # Load AI trainer
        self.ai_trainer = AITrainer()
        self.ai_trainer.load_trained_model()
        
        # Load embedding model cho job search
        self.embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        
        # Connect to vector database
        try:
            self.chroma_client = chromadb.PersistentClient(
                path='./data/vector_db',
                settings=Settings(anonymized_telemetry=False)
            )
            self.collection = self.chroma_client.get_collection("job_postings")
            print("‚úÖ ƒê√£ k·∫øt n·ªëi vector database")
        except:
            print("‚ö†Ô∏è Ch∆∞a c√≥ vector database. Ch·∫°y training jobs tr∆∞·ªõc!")
            self.collection = None
        
        # Database connector
        self.db = DatabaseConnector()
        
        # AI SQL Generator with RAG (required)
        self.ai_sql_executor = None
        if AI_SQL_AVAILABLE:
            try:
                # Initialize v·ªõi RAG enabled (use_rag=True by default)
                self.ai_sql_executor = SmartSQLExecutor(self.db, provider='groq', use_rag=True)
                print("‚úÖ AI SQL Generator initialized (Groq + RAG)")
            except ValueError as e:
                print(f"‚ùå AI SQL Generator initialization failed: {e}")
                print("üí° Please run: python train_sql_examples.py")
                self.ai_sql_executor = None
            except Exception as e:
                print(f"‚ö†Ô∏è AI SQL Generator failed to initialize: {e}")
                print("üí° Tips:")
                print("   1. Add GROQ_API_KEY to .env file")
                print("   2. Run: python train_sql_examples.py")
                self.ai_sql_executor = None
        
        # Context memory ƒë·ªÉ nh·ªõ conversation
        self.context = {
            'last_salary': None,
            'last_position': None,
            'last_location': None
        }
        
        print("‚úÖ Chatbot s·∫µn s√†ng!")
    
    def chat(self, message):
        """
        X·ª≠ l√Ω tin nh·∫Øn t·ª´ user
        
        Args:
            message: Tin nh·∫Øn t·ª´ user
            
        Returns:
            Dict ch·ª©a response v√† metadata
        """
        message = message.strip()
        
        # B∆Ø·ªöC 1: Check AI trained responses cho greeting/thanks/goodbye/help FIRST
        # ∆Øu ti√™n cao nh·∫•t ƒë·ªÉ chatbot t·ª± nhi√™n h∆°n
        ai_result = self.ai_trainer.predict(message, threshold=0.7)
        
        non_job_tags = ['greeting', 'goodbye', 'thanks', 'help']
        if ai_result and ai_result['tag'] in non_job_tags and ai_result['confidence'] > 0.7:
            # Reset context cho c√°c tag kh√¥ng li√™n quan job
            self.context = {
                'last_position': None,
                'last_salary': None,
                'last_location': None
            }
            
            return {
                'success': True,
                'message': message,
                'response': ai_result['response'],
                'type': 'trained',
                'tag': ai_result['tag'],
                'confidence': ai_result['confidence']
            }
        
        # B∆Ø·ªöC 2: Try AI SQL Generator (cho c√°c c√¢u h·ªèi ph·ª©c t·∫°p)
        if self.ai_sql_executor:
            try:
                print(f"\n{'='*80}")
                print(f"ü§ñ AI SQL Generator")
                print(f"‚ùì Question: {message}")
                print(f"{'='*80}")
                
                sql_result = self.ai_sql_executor.query(message)
                
                if sql_result['success']:
                    print(f"\n‚úÖ SQL Generated Successfully!")
                    print(f"üíª SQL: {sql_result.get('sql', 'N/A')}")
                    print(f"üìä Query Type: {sql_result.get('query_type', 'N/A')}")
                    print(f"{'='*80}\n")
                    
                    response = self.ai_sql_executor.format_results(sql_result)
                    return {
                        'success': True,
                        'message': message,
                        'response': response,
                        'type': 'ai_sql_query',
                        'sql': sql_result.get('sql'),
                        'query_type': sql_result.get('query_type')
                    }
                else:
                    print(f"\n‚ö†Ô∏è AI SQL failed: {sql_result.get('message', 'Unknown error')}")
                    print(f"{'='*80}\n")
                    
            except Exception as e:
                print(f"\n‚ùå AI SQL error: {e}")
                print(f"{'='*80}\n")
                # Fallback to normal flow
        
        # Extract context t·ª´ message
        self._extract_context(message)
        
        # PRIORITY CHECK: N·∫øu c√≥ position + salary/location ‚Üí Job search ngay
        # B·ªè qua AI trained responses ƒë·ªÉ tr√°nh nh·∫ßm v·ªõi salary_question
        has_position = self.context['last_position'] is not None
        has_salary = self.context['last_salary'] is not None
        has_location = self.context['last_location'] is not None
        
        if has_position and (has_salary or has_location):
            # C√≥ position + (salary ho·∫∑c location) ‚Üí Job search ngay
            jobs = self.search_jobs_with_context(message)
            response = self._format_job_results(jobs, message)
            return {
                'success': True,
                'message': message,
                'response': response,
                'type': 'job_search',
                'jobs': jobs,
                'context': self.context.copy()
            }
        
        # B∆∞·ªõc 2: X·ª≠ l√Ω AI trained responses (ai_result ƒë√£ ƒë∆∞·ª£c predict ·ªü tr√™n)
        if ai_result and ai_result['tag'] != 'unknown' and ai_result['confidence'] > 0.7:
            # C√≥ trained response v·ªõi confidence cao
            
            # N·∫øu tag l√† job_statistics ‚Üí Show statistics
            if ai_result['tag'] == 'job_statistics':
                stats = self.get_job_statistics()
                response = self._format_statistics(stats)
                return {
                    'success': True,
                    'message': message,
                    'response': response,
                    'type': 'statistics',
                    'statistics': stats
                }
            
            # N·∫øu tag l√† today_jobs ‚Üí Show only today's jobs count
            if ai_result['tag'] == 'today_jobs':
                stats = self.get_job_statistics()
                response = self._format_today_jobs(stats)
                return {
                    'success': True,
                    'message': message,
                    'response': response,
                    'type': 'today_jobs',
                    'today_count': stats['today_jobs'] if stats else 0
                }
            
            # N·∫øu tag l√† position_inquiry ‚Üí Trigger job search
            if ai_result['tag'] == 'position_inquiry':
                jobs = self.search_jobs(message)
                response = self._format_job_results(jobs, message)
                return {
                    'success': True,
                    'message': message,
                    'response': response,
                    'type': 'job_search',
                    'jobs': jobs
                }
            
            # N·∫øu tag l√† location_search ‚Üí Trigger job search by location
            if ai_result['tag'] == 'location_search':
                jobs = self.search_jobs_with_context(message)
                response = self._format_job_results(jobs, message)
                return {
                    'success': True,
                    'message': message,
                    'response': response,
                    'type': 'job_search',
                    'jobs': jobs,
                    'context': self.context.copy()
                }
            
            return {
                'success': True,
                'message': message,
                'response': ai_result['response'],
                'type': 'trained',
                'tag': ai_result['tag'],
                'confidence': ai_result['confidence']
            }
        
        # B∆∞·ªõc 3: Check n·∫øu ch·ªâ c√≥ position (kh√¥ng c√≥ salary/location)
        has_position = self.context['last_position'] is not None
        has_salary = self.context['last_salary'] is not None
        has_location = self.context['last_location'] is not None
        
        # Trigger job search n·∫øu:
        # 1. Ch·ªâ c√≥ position
        # 2. C√≥ salary/location + job keywords (nh∆∞ng kh√¥ng c√≥ position)
        if has_position:
            jobs = self.search_jobs_with_context(message)
            response = self._format_job_results(jobs, message)
            return {
                'success': True,
                'message': message,
                'response': response,
                'type': 'job_search',
                'jobs': jobs,
                'context': self.context.copy()
            }
        
        if (has_salary and self._has_job_keywords(message)) or (has_location and self._has_job_keywords(message)):
            jobs = self.search_jobs_with_context(message)
            response = self._format_job_results(jobs, message)
            return {
                'success': True,
                'message': message,
                'response': response,
                'type': 'job_search',
                'jobs': jobs,
                'context': self.context.copy()
            }
        
        # B∆∞·ªõc 4: Check n·∫øu l√† job search (keywords)
        if self._is_job_search(message):
            jobs = self.search_jobs_with_context(message)
            response = self._format_job_results(jobs, message)
            return {
                'success': True,
                'message': message,
                'response': response,
                'type': 'job_search',
                'jobs': jobs,
                'context': self.context.copy()
            }
        
        # B∆∞·ªõc 5: Fallback response
        return {
            'success': True,
            'message': message,
            'response': "Xin l·ªói, t√¥i ch∆∞a hi·ªÉu c√¢u h·ªèi n√†y. B·∫°n c√≥ th·ªÉ h·ªèi t√¥i v·ªÅ:\n‚Ä¢ T√¨m vi·ªác l√†m\n‚Ä¢ Y√™u c·∫ßu c√¥ng vi·ªác\n‚Ä¢ M·ª©c l∆∞∆°ng\n‚Ä¢ C√°ch ·ª©ng tuy·ªÉn\n‚Ä¢ Th·ªëng k√™ jobs (VD: 'Danh s√°ch job ·ªü H√† N·ªôi', 'Top 5 job l∆∞∆°ng cao')",
            'type': 'fallback'
        }
    
    def _extract_context(self, message):
        """Extract context t·ª´ message (salary, position, location)"""
        import re
        message_lower = message.lower()
        
        # Detect n·∫øu c√≥ position/location/salary m·ªõi
        new_position = None
        new_location = None
        new_salary = None
        
        # Extract position - ∆Øu ti√™n specific positions (d√†i h∆°n) tr∆∞·ªõc
        positions = [
            # Specific positions (2+ words) - ∆∞u ti√™n cao nh·∫•t
            'business analyst', 'data analyst', 'product manager',
            'frontend developer', 'backend developer', 'fullstack developer',
            'mobile developer', 'ios developer', 'android developer',
            'ui/ux designer', 'graphic designer',
            # Single word positions - specific
            'frontend', 'backend', 'fullstack', 'mobile',
            'designer', 'tester', 'qa', 'devops',
            'marketing', 'sale', 'hr',
            # Generic (cu·ªëi c√πng)
            'developer'
        ]
        for pos in positions:
            if pos in message_lower:
                new_position = pos
                break
        
        # Extract location
        locations = {
            'h√† n·ªôi': 'H√† N·ªôi',
            'hanoi': 'H√† N·ªôi',
            'hcm': 'H·ªì Ch√≠ Minh',
            'h·ªì ch√≠ minh': 'H·ªì Ch√≠ Minh',
            's√†i g√≤n': 'H·ªì Ch√≠ Minh',
            'ƒë√† n·∫µng': 'ƒê√† N·∫µng'
        }
        for key, value in locations.items():
            if key in message_lower:
                new_location = value
                break
        
        # Extract salary - CH·ªà extract khi c√≥ t·ª´ kh√≥a v·ªÅ l∆∞∆°ng
        salary_patterns = [
            # C√≥ t·ª´ "l∆∞∆°ng" tr∆∞·ªõc
            r'l∆∞∆°ng\s+(\d+)\s*(?:tri·ªáu|tr|million|m)?',
            r'm·ª©c\s+l∆∞∆°ng\s+(\d+)\s*(?:tri·ªáu|tr|million|m)?',
            r'thu\s+nh·∫≠p\s+(\d+)\s*(?:tri·ªáu|tr|million|m)?',
            r'salary\s+(\d+)\s*(?:tri·ªáu|tr|million|m)?',
            # C√≥ t·ª´ "l∆∞∆°ng" sau
            r'(\d+)\s*(?:tri·ªáu|tr)\s+l∆∞∆°ng',
            # C√≥ "t·ª´", "tr·ªü l√™n", ">", ">="
            r't·ª´\s+(\d+)\s*(?:tri·ªáu|tr)',
            r'(\d+)\s*(?:tri·ªáu|tr)\s+tr·ªü\s+l√™n',
            r'>=?\s*(\d+)\s*(?:tri·ªáu|tr)',
            r'>\s*(\d+)\s*(?:tri·ªáu|tr)'
        ]
        
        for pattern in salary_patterns:
            match = re.search(pattern, message_lower)
            if match:
                amount = int(match.group(1))
                new_salary = amount * 1000000  # Convert to VND
                break
        
        # Logic reset context:
        # 1. N·∫øu message CH·ªà c√≥ location (kh√¥ng c√≥ position/salary) 
        #    ‚Üí Reset position c≈©
        # 2. N·∫øu message CH·ªà c√≥ position (kh√¥ng c√≥ location/salary)
        #    ‚Üí Reset location c≈©
        if new_location and not new_position and not new_salary:
            # Message ch·ªâ c√≥ location ‚Üí Clear position c≈©
            self.context['last_position'] = None
            self.context['last_salary'] = None
            self.context['last_location'] = new_location
        elif new_position and not new_location and not new_salary:
            # Message ch·ªâ c√≥ position ‚Üí Clear location c≈©
            self.context['last_position'] = new_position
            self.context['last_location'] = None
            self.context['last_salary'] = None
        else:
            # Update context b√¨nh th∆∞·ªùng
            if new_position:
                self.context['last_position'] = new_position
            if new_location:
                self.context['last_location'] = new_location
            if new_salary:
                self.context['last_salary'] = new_salary
    
    def search_jobs_with_context(self, query):
        """Search jobs v·ªõi context filters - ∆Øu ti√™n d√πng AI SQL Generator"""
        
        # OPTION 1: Try AI SQL Generator first (n·∫øu c√≥ context)
        if self.ai_sql_executor and (self.context['last_position'] or self.context['last_location'] or self.context['last_salary']):
            try:
                # Build natural language query t·ª´ context
                nl_query_parts = []
                
                if self.context['last_position']:
                    nl_query_parts.append(f"v·ªã tr√≠ {self.context['last_position']}")
                
                if self.context['last_location']:
                    nl_query_parts.append(f"·ªü {self.context['last_location']}")
                
                if self.context['last_salary']:
                    salary_m = int(self.context['last_salary'] / 1000000)
                    nl_query_parts.append(f"l∆∞∆°ng t·ª´ {salary_m} tri·ªáu tr·ªü l√™n")
                
                nl_query = "Danh s√°ch vi·ªác l√†m " + " ".join(nl_query_parts)
                
                print(f"\nü§ñ Using AI SQL for job search: {nl_query}")
                
                # Generate SQL
                sql_result = self.ai_sql_executor.query(nl_query)
                
                if sql_result['success'] and sql_result.get('results'):
                    print(f"‚úÖ AI SQL returned {len(sql_result['results'])} jobs")
                    
                    # Convert SQL results to job format
                    jobs = []
                    for row in sql_result['results'][:10]:
                        job = {
                            'job_id': row.get('job_id', 0),
                            'position': row.get('position', ''),
                            'title': row.get('title', ''),
                            'location': row.get('location', ''),
                            'salary_min': row.get('salary_min', 0),
                            'salary_max': row.get('salary_max', 0),
                            'work_type': row.get('work_type', ''),
                            'posted_at': row.get('posted_at', ''),
                            'relevance': 0.9  # High relevance v√¨ exact match
                        }
                        jobs.append(job)
                    
                    return jobs[:5]
                else:
                    print(f"‚ö†Ô∏è AI SQL failed or no results, fallback to vector search")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è AI SQL error in job search: {e}")
                # Fallback to vector search
        
        # OPTION 2: Fallback to ChromaDB vector search
        print(f"\nüîç Using ChromaDB vector search")
        
        # Build enhanced query v·ªõi context
        search_query = query
        if self.context['last_location'] and not self.context['last_position']:
            search_query = f"vi·ªác l√†m {self.context['last_location']}"
        elif self.context['last_position'] and self.context['last_location']:
            search_query = f"{self.context['last_position']} {self.context['last_location']}"
        
        # Build ChromaDB metadata filters (WHERE clause)
        where_filters = {}
        
        # Filter by location (exact match)
        if self.context['last_location']:
            where_filters['location'] = self.context['last_location']
        
        # Filter by salary (>=)
        if self.context['last_salary']:
            where_filters['salary_max'] = {'$gte': float(self.context['last_salary'])}
        
        # Search v·ªõi metadata filters
        jobs = self.search_jobs_with_filters(search_query, where_filters, top_k=20)
        
        if not jobs:
            return []
        
        # Post-filter by position (v√¨ ChromaDB kh√¥ng support LIKE/CONTAINS)
        if self.context['last_position']:
            import re
            pos_filter = self.context['last_position'].lower()
            filtered_jobs = []
            
            # T·∫°o pattern v·ªõi word boundary
            pattern = r'\b' + re.escape(pos_filter) + r'\b'
            
            print(f"\nüîç Filtering jobs with position: '{pos_filter}'")
            print(f"Pattern: {pattern}")
            
            for job in jobs:
                job_pos = job.get('position', '').lower()
                job_title = job.get('title', '').lower()
                
                # Check match
                pos_match = re.search(pattern, job_pos)
                title_match = re.search(pattern, job_title)
                
                print(f"\nJob: {job.get('position', 'N/A')} - {job.get('title', 'N/A')}")
                print(f"  Position match: {bool(pos_match)}")
                print(f"  Title match: {bool(title_match)}")
                
                if pos_match or title_match:
                    filtered_jobs.append(job)
                    print(f"  ‚úÖ ADDED")
                else:
                    print(f"  ‚ùå FILTERED OUT")
                
                if len(filtered_jobs) >= 5:
                    break
            
            print(f"\n‚úÖ Filtered: {len(filtered_jobs)} jobs")
            return filtered_jobs
        
        # N·∫øu kh√¥ng c√≥ position filter, return top 5
        return jobs[:5]
    
    def _has_job_keywords(self, message):
        """Check n·∫øu message c√≥ keywords li√™n quan ƒë·∫øn job"""
        message_lower = message.lower()
        job_keywords = [
            'vi·ªác', 'job', 'c√¥ng vi·ªác', 'tuy·ªÉn', '·ª©ng tuy·ªÉn',
            'l∆∞∆°ng', 'salary', 'm·ª©c l∆∞∆°ng', 'thu nh·∫≠p'
        ]
        return any(keyword in message_lower for keyword in job_keywords)
    
    def _is_job_search(self, message):
        """Check n·∫øu message l√† job search"""
        message_lower = message.lower()
        
        # Keywords r√µ r√†ng v·ªÅ job search
        job_search_keywords = [
            't√¨m vi·ªác', 'vi·ªác l√†m', 'c√¥ng vi·ªác', 'job', 'tuy·ªÉn d·ª•ng',
            't√¨m', 'c√≥ vi·ªác', 'c·∫ßn tuy·ªÉn'
        ]
        
        # Job positions
        job_positions = [
            'developer', 'dev', 'l·∫≠p tr√¨nh', 'programmer',
            'frontend', 'front-end', 'backend', 'back-end', 'fullstack', 'full-stack',
            'mobile', 'android', 'ios', 'react', 'angular', 'vue', 'nodejs',
            'java', 'python', 'php', '.net', 'c#', 'javascript',
            'designer', 'thi·∫øt k·∫ø', 'ui/ux', 'graphic',
            'tester', 'qa', 'ki·ªÉm th·ª≠',
            'devops', 'sysadmin', 'network',
            'data analyst', 'data scientist', 'business analyst', 'ba',
            'product manager', 'pm', 'project manager',
            'marketing', 'sale', 'hr', 'nh√¢n s·ª±', 'accountant', 'k·∫ø to√°n'
        ]
        
        # Locations
        locations = [
            'h√† n·ªôi', 'hanoi', 'hn',
            'h·ªì ch√≠ minh', 'hcm', 's√†i g√≤n', 'saigon',
            'ƒë√† n·∫µng', 'danang', 'h·∫£i ph√≤ng', 'c·∫ßn th∆°'
        ]
        
        # Check job search keywords
        if any(keyword in message_lower for keyword in job_search_keywords):
            return True
        
        # Check n·∫øu ch·ªâ g√µ position name (VD: "frontend", "developer")
        # V√† message ng·∫Øn (< 20 k√Ω t·ª±) ‚Üí C√≥ th·ªÉ l√† job search
        if len(message) < 20:
            if any(pos in message_lower for pos in job_positions):
                return True
            if any(loc in message_lower for loc in locations):
                return True
        
        return False
    
    def search_jobs(self, query, top_k=5):
        """T√¨m ki·∫øm jobs - ∆Øu ti√™n d√πng AI SQL Generator"""
        
        # OPTION 1: Try AI SQL Generator first
        if self.ai_sql_executor:
            try:
                print(f"\nü§ñ Using AI SQL for basic job search: {query}")
                
                # Generate SQL
                sql_result = self.ai_sql_executor.query(f"Danh s√°ch vi·ªác l√†m {query}")
                
                if sql_result['success'] and sql_result.get('results'):
                    print(f"‚úÖ AI SQL returned {len(sql_result['results'])} jobs")
                    
                    # Convert SQL results to job format
                    jobs = []
                    for row in sql_result['results'][:top_k]:
                        job = {
                            'job_id': row.get('job_id', 0),
                            'position': row.get('position', ''),
                            'title': row.get('title', ''),
                            'location': row.get('location', ''),
                            'salary_min': row.get('salary_min', 0),
                            'salary_max': row.get('salary_max', 0),
                            'work_type': row.get('work_type', ''),
                            'posted_at': row.get('posted_at', ''),
                            'relevance': 0.85  # High relevance
                        }
                        jobs.append(job)
                    
                    return jobs
                else:
                    print(f"‚ö†Ô∏è AI SQL failed or no results, fallback to vector search")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è AI SQL error in basic search: {e}")
                # Fallback to vector search
        
        # OPTION 2: Fallback to ChromaDB vector search
        print(f"\nüîç Using ChromaDB vector search for: {query}")
        return self.search_jobs_with_filters(query, where_filters=None, top_k=top_k)
    
    def search_jobs_with_filters(self, query, where_filters=None, top_k=5):
        """T√¨m ki·∫øm jobs v·ªõi ChromaDB metadata filters (WHERE clause)"""
        if not self.collection:
            return []
        
        try:
            # Create embedding
            query_embedding = self.embedding_model.encode([query])[0]
            
            # Build query parameters
            query_params = {
                'query_embeddings': [query_embedding.tolist()],
                'n_results': top_k
            }
            
            # Add WHERE filters n·∫øu c√≥
            if where_filters:
                query_params['where'] = where_filters
            
            # Search v·ªõi filters
            results = self.collection.query(**query_params)
            
            jobs = []
            if results['ids'] and results['ids'][0]:
                for i in range(len(results['ids'][0])):
                    metadata = results['metadatas'][0][i]
                    distance = results['distances'][0][i]
                    
                    # Fix relevance calculation
                    # ChromaDB distance c√†ng nh·ªè c√†ng gi·ªëng
                    # Convert to similarity score (0-100%)
                    if distance < 0:
                        distance = abs(distance)
                    
                    # C√¥ng th·ª©c c·∫£i thi·ªán: 
                    # relevance = 100 / (1 + distance * 10)
                    # ƒêi·ªÅu n√†y cho score cao h∆°n v√† d·ªÖ hi·ªÉu h∆°n
                    relevance = min(100, 100 / (1 + distance * 10))
                    
                    # Boost relevance cho jobs m·ªõi ƒëƒÉng
                    # N·∫øu job c√≥ posted_at trong metadata
                    if 'posted_at' in metadata:
                        from datetime import datetime, timedelta
                        try:
                            posted_date = datetime.fromisoformat(str(metadata['posted_at']))
                            days_ago = (datetime.now() - posted_date).days
                            
                            # Boost jobs trong 7 ng√†y g·∫ßn nh·∫•t
                            if days_ago <= 7:
                                boost_factor = 1.0 + (7 - days_ago) * 0.05  # Max boost 35%
                                relevance = min(100, relevance * boost_factor)
                        except:
                            pass
                    
                    job = {
                        'job_id': metadata['job_id'],
                        'position': metadata.get('position', ''),
                        'title': metadata.get('title', ''),
                        'location': metadata.get('location', ''),
                        'salary_min': metadata.get('salary_min', 0),
                        'salary_max': metadata.get('salary_max', 0),
                        'work_type': metadata.get('work_type', ''),
                        'posted_at': metadata.get('posted_at', ''),
                        'relevance': relevance / 100  # Normalize v·ªÅ 0-1
                    }
                    jobs.append(job)
            
            # Sort by relevance (sau khi boost) + posted_at
            # ∆Øu ti√™n: relevance cao + ng√†y ƒëƒÉng m·ªõi
            def sort_key(job):
                from datetime import datetime
                relevance_score = job['relevance']
                
                # T√≠nh recency score (0-1)
                recency_score = 0
                if job.get('posted_at'):
                    try:
                        posted_date = datetime.fromisoformat(str(job['posted_at']))
                        days_ago = (datetime.now() - posted_date).days
                        # Jobs m·ªõi h∆°n c√≥ score cao h∆°n
                        recency_score = max(0, 1 - (days_ago / 30))  # Decay trong 30 ng√†y
                    except:
                        pass
                
                # K·∫øt h·ª£p: 70% relevance + 30% recency
                combined_score = (relevance_score * 0.7) + (recency_score * 0.3)
                return combined_score
            
            jobs.sort(key=sort_key, reverse=True)
            
            # Return top_k jobs
            return jobs[:top_k]
        except Exception as e:
            print(f"‚ùå L·ªói search: {e}")
            return []
    
    def get_job_statistics(self):
        """L·∫•y th·ªëng k√™ jobs t·ª´ database - ∆Øu ti√™n d√πng AI SQL"""
        
        # OPTION 1: Try AI SQL Generator for statistics
        if self.ai_sql_executor:
            try:
                print(f"\nü§ñ Using AI SQL for statistics")
                
                # Get multiple statistics
                stats_result = {}
                
                # 1. Total active jobs
                total_query = self.ai_sql_executor.query("C√≥ bao nhi√™u job ƒëang tuy·ªÉn?")
                if total_query['success'] and total_query.get('result') is not None:
                    stats_result['total_active'] = total_query['result']
                
                # 2. Today's jobs
                today_query = self.ai_sql_executor.query("C√≥ bao nhi√™u job ƒëƒÉng h√¥m nay?")
                if today_query['success'] and today_query.get('result') is not None:
                    stats_result['today_jobs'] = today_query['result']
                else:
                    stats_result['today_jobs'] = 0
                
                # 3. Top positions
                positions_query = self.ai_sql_executor.query("Top 5 v·ªã tr√≠ c√≥ nhi·ªÅu job nh·∫•t")
                if positions_query['success'] and positions_query.get('results'):
                    stats_result['top_positions'] = []
                    for row in positions_query['results'][:5]:
                        stats_result['top_positions'].append({
                            'position': row.get('position', 'N/A'),
                            'count': row.get('job_count', 0)
                        })
                
                # 4. Locations
                locations_query = self.ai_sql_executor.query("Th·ªëng k√™ job theo ƒë·ªãa ƒëi·ªÉm")
                if locations_query['success'] and locations_query.get('results'):
                    stats_result['locations'] = []
                    for row in locations_query['results'][:5]:
                        stats_result['locations'].append({
                            'location': row.get('location', 'N/A'),
                            'count': row.get('job_count', 0)
                        })
                
                # 5. Categories
                categories_query = self.ai_sql_executor.query("Th·ªëng k√™ job theo danh m·ª•c")
                if categories_query['success'] and categories_query.get('results'):
                    stats_result['categories'] = []
                    for row in categories_query['results'][:5]:
                        stats_result['categories'].append({
                            'category': row.get('name', 'N/A'),
                            'count': row.get('job_count', 0)
                        })
                
                # If we got at least total_active, return AI SQL results
                if 'total_active' in stats_result:
                    print(f"‚úÖ AI SQL statistics successful")
                    return stats_result
                else:
                    print(f"‚ö†Ô∏è AI SQL statistics incomplete, fallback to DB")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è AI SQL error in statistics: {e}")
                # Fallback to DB
        
        # OPTION 2: Fallback to database query
        print(f"\nüîç Using database for statistics")
        if not self.db.connection:
            self.db.connect()
        
        return self.db.get_job_statistics()
    
    def _format_today_jobs(self, stats):
        """Format today's jobs count - CH·ªà ƒë·∫øm s·ªë l∆∞·ª£ng"""
        if not stats:
            return "üòî Xin l·ªói, kh√¥ng th·ªÉ l·∫•y th√¥ng tin l√∫c n√†y."
        
        today_count = stats['today_jobs']
        total_active = stats['total_active']
        
        response = f"üìÖ **VI·ªÜC L√ÄM H√îM NAY**\n\n"
        
        if today_count == 0:
            response += "üòî H√¥m nay ch∆∞a c√≥ vi·ªác l√†m m·ªõi ƒë∆∞·ª£c ƒëƒÉng.\n\n"
        else:
            response += f"üéâ H√¥m nay c√≥ **{today_count}** vi·ªác l√†m m·ªõi ƒë∆∞·ª£c ƒëƒÉng!\n\n"
        
        response += f"üíº T·ªïng s·ªë vi·ªác l√†m ƒëang tuy·ªÉn: **{total_active}** jobs\n\n"
        response += "üí° H·ªèi t√¥i v·ªÅ v·ªã tr√≠ b·∫°n quan t√¢m ƒë·ªÉ t√¨m vi·ªác ph√π h·ª£p!"
        
        return response
    
    def _format_statistics(self, stats):
        """Format statistics th√†nh response text"""
        if not stats:
            return "üòî Xin l·ªói, kh√¥ng th·ªÉ l·∫•y th·ªëng k√™ l√∫c n√†y."
        
        response = "üìä **TH·ªêNG K√ä VI·ªÜC L√ÄM**\n\n"
        
        # T·ªïng quan
        response += f"üìà **T·ªïng quan:**\n"
        response += f"‚Ä¢ T·ªïng s·ªë vi·ªác l√†m ƒëang tuy·ªÉn: **{stats['total_active']}** jobs\n"
        response += f"‚Ä¢ Vi·ªác l√†m m·ªõi h√¥m nay: **{stats['today_jobs']}** jobs\n\n"
        
        # Top positions
        if stats['top_positions']:
            response += f"üî• **Top 5 v·ªã tr√≠ hot:**\n"
            for i, pos in enumerate(stats['top_positions'], 1):
                response += f"{i}. {pos['position']}: **{pos['count']}** jobs\n"
            response += "\n"
        
        # Locations
        if stats['locations']:
            response += f"üìç **Theo ƒë·ªãa ƒëi·ªÉm:**\n"
            for loc in stats['locations'][:5]:
                response += f"‚Ä¢ {loc['location']}: **{loc['count']}** jobs\n"
            response += "\n"
        
        # Categories
        if stats['categories']:
            response += f"üìÇ **Theo danh m·ª•c:**\n"
            for cat in stats['categories'][:5]:
                response += f"‚Ä¢ {cat['category']}: **{cat['count']}** jobs\n"
        
        response += "\nüí° H·ªèi t√¥i v·ªÅ v·ªã tr√≠ b·∫°n quan t√¢m ƒë·ªÉ t√¨m vi·ªác ph√π h·ª£p!"
        
        return response
    
    def _format_job_results(self, jobs, query):
        """Format job results th√†nh response text"""
        if not jobs:
            # Build context message
            context_parts = []
            if self.context['last_position']:
                context_parts.append(f"v·ªã tr√≠ **{self.context['last_position']}**")
            if self.context['last_salary']:
                salary_m = self.context['last_salary'] / 1000000
                context_parts.append(f"l∆∞∆°ng t·ª´ **{salary_m:.0f} tri·ªáu**")
            if self.context['last_location']:
                context_parts.append(f"t·∫°i **{self.context['last_location']}**")
            
            context_text = " ".join(context_parts) if context_parts else f"'{query}'"
            
            return f"üòî Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y c√¥ng vi·ªác n√†o {context_text}.\n\nB·∫°n c√≥ th·ªÉ th·ª≠:\n‚Ä¢ Gi·∫£m y√™u c·∫ßu v·ªÅ l∆∞∆°ng\n‚Ä¢ Thay ƒë·ªïi v·ªã tr√≠\n‚Ä¢ T√¨m ·ªü ƒë·ªãa ƒëi·ªÉm kh√°c"
        
        # Build header v·ªõi context
        header_parts = []
        if self.context['last_position']:
            header_parts.append(f"**{self.context['last_position']}**")
        if self.context['last_salary']:
            salary_m = self.context['last_salary'] / 1000000
            header_parts.append(f"l∆∞∆°ng t·ª´ **{salary_m:.0f} tri·ªáu**")
        if self.context['last_location']:
            header_parts.append(f"t·∫°i **{self.context['last_location']}**")
        
        header = " ".join(header_parts) if header_parts else "ph√π h·ª£p"
        
        response = f"üéØ T√¥i t√¨m th·∫•y **{len(jobs)}** c√¥ng vi·ªác {header}:\n\n"
        
        for i, job in enumerate(jobs, 1):
            salary_min = int(job['salary_min'] / 1000000)
            salary_max = int(job['salary_max'] / 1000000)
            
            # Check if job is new (posted within 7 days)
            is_new = False
            if job.get('posted_at'):
                from datetime import datetime
                try:
                    posted_date = datetime.fromisoformat(str(job['posted_at']))
                    days_ago = (datetime.now() - posted_date).days
                    is_new = days_ago <= 7
                except:
                    pass
            
            new_badge = " üÜï" if is_new else ""
            
            response += f"**{i}. {job['position']}**{new_badge} (ID: {job['job_id']})\n"
            response += f"   üìã {job['title']}\n"
            response += f"   üìç {job['location']}\n"
            response += f"   üí∞ {salary_min}-{salary_max} tri·ªáu VNƒê\n"
            response += f"   üíº {job['work_type']}\n"
            response += f"   ‚ú® ƒê·ªô ph√π h·ª£p: {job['relevance']:.1%}\n\n"
        
        return response


if __name__ == "__main__":
    # Test chatbot
    chatbot = HRChatbot()
    
    print("\n" + "="*60)
    print("HR CHATBOT TEST")
    print("="*60)
    
    test_messages = [
        "xin ch√†o",
        "t√¨m vi·ªác l√†m developer",
        "c·∫£m ∆°n",
        "y√™u c·∫ßu g√¨",
        "t·∫°m bi·ªát"
    ]
    
    for msg in test_messages:
        print(f"\nüë§ User: {msg}")
        result = chatbot.chat(msg)
        print(f"ü§ñ Bot ({result['type']}): {result['response']}")
